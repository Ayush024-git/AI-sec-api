from fastapi import FastAPI, HTTPException, Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
import requests
import os
import json

# Initialize FastAPI
app = FastAPI()

security = HTTPBearer()

# Load client auth key
CUSTOMER_KEY = os.getenv("API_KEY")

# Input schema
class Input(BaseModel):
    text: str

# Root health route
@app.get("/")
def root():
    return {"status": "AI Safety API running (Local TinyLlama)"}

# Debug route
@app.get("/debug-key")
def debug_key():
    return {"loaded_api_key": CUSTOMER_KEY}

# Safety check endpoint
@app.post("/check")
def check(
    input: Input,
    credentials: HTTPAuthorizationCredentials = Depends(security)
):

    # üîê API key protection
    if not CUSTOMER_KEY:
        raise HTTPException(status_code=500, detail="Server API_KEY not set")

    token = credentials.credentials
    if token != CUSTOMER_KEY:
        raise HTTPException(status_code=401, detail="Unauthorized")

    # üî• Stronger prompt forcing rewrite
    prompt = f"""
You are an advanced AI Safety Moderation and Response Engine.

Analyze the input text and respond in STRICT JSON ONLY.

You MUST include ALL fields:

safe ‚Üí true or false
safety_score ‚Üí 0‚Äì100
risk_category ‚Üí category
reason ‚Üí explanation
safe_response ‚Üí safer rewritten version

If unsafe ‚Üí rewrite safely.
If safe ‚Üí repeat input politely.

Text:
\"\"\"{input.text}\"\"\"
"""

    try:
        # üîó Call TinyLlama
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "tinyllama",
                "prompt": prompt,
                "stream": False
            },
            timeout=120
        )

        if response.status_code != 200:
            raise HTTPException(
                status_code=500,
                detail=f"Ollama error: {response.text}"
            )

        raw_output = response.json().get("response", "")

        # Try parsing JSON
        try:
            parsed = json.loads(raw_output)
        except:
            parsed = {}

        # üõü Fallback rewrite if missing
        if "safe_response" not in parsed:

            fallback_prompt = f"""
Rewrite this text safely and politely:

{input.text}
"""

            fallback = requests.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "tinyllama",
                    "prompt": fallback_prompt,
                    "stream": False
                }
            )

            rewrite = fallback.json().get("response", "")

            parsed["safe_response"] = rewrite.strip()

        # Fill missing fields safely
        parsed.setdefault("safe", False)
        parsed.setdefault("safety_score", 50)
        parsed.setdefault("risk_category", "Unknown")
        parsed.setdefault("reason", "Generated by fallback logic")

        return parsed

    except requests.exceptions.ConnectionError:
        raise HTTPException(
            status_code=500,
            detail="Ollama not running on localhost:11434"
        )

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=str(e)
        )
